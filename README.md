# DealerFlow Cloud - AI Lead Generator

An AI-powered B2B lead generation system that discovers potential customers and technology partners for automotive dealership management systems.

## ğŸ¯ What It Does

Uses **open-source LLMs** (Mistral 7B / Llama 3.1) and multi-agent architecture to intelligently discover and evaluate:

- **Top 10 Potential Customers**: Automotive dealerships likely to buy DealerFlow Cloud
- **Top 10 Potential Partners**: Technology companies that could integrate with the platform

## âœ¨ Key Features

âœ… **Natural Language Interface** - Specify requirements in plain English
âœ… **Multi-Agent System** - 5 specialized AI agents working together
âœ… **Open-Source LLMs** - Mistral 7B / Llama 3.1 via Ollama
âœ… **AI-Optimized Search** - Tavily API (1,000 free searches/month)
âœ… **Prompt Tracing** - Track and optimize LLM interactions
âœ… **Smart Filtering** - Parent/subsidiary detection, competitor exclusion
âœ… **Repeatable Results** - Deterministic prompts and result caching

## ğŸš€ Quick Start

### Prerequisites

- Python 3.9+
- Ollama (local LLM runtime)

### Installation

```bash
# 1. Install Ollama
brew install ollama  # macOS
ollama pull mistral:7b

# To run if already installed
ollama serve

# 2. Clone and setup
git clone <your-repo-url>
cd EaseVerticalAI
./setup.sh

# 3. Add Tavily API key to .env
TAVILY_API_KEY=your_key_here  # Get free key at https://tavily.com

# 4. Run the app
streamlit run app.py
```

Open browser to `http://localhost:8501`

**See [Complete Guide](docs/GUIDE.md) for detailed setup instructions**

## ğŸ—ï¸ Architecture

### Multi-Agent System

```
User Input (Natural Language)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Intent Classifier Agent â”‚ â†’ Customer / Partner / Both?
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Research Agent          â”‚ â†’ Generate queries, search, filter
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Enrichment Agent        â”‚ â†’ Gather company details
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Scoring Agent           â”‚ â†’ Evaluate fit, rank results
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Top 10 Results (JSON)
```

### Technology Stack

- **LLM**: Ollama (Mistral 7B / Llama 3.1 8B)
- **Search**: Tavily AI (AI-optimized for LLMs)
- **UI**: Streamlit
- **Language**: Python 3.9+
- **Caching**: JSON-based results cache

See data/results_cache/ for complete results.

## ğŸ“ Project Structure

```
EaseVerticalAI/
â”œâ”€â”€ agents/                     # AI agents
â”‚   â”œâ”€â”€ intent_classifier.py   # Classify user intent
â”‚   â”œâ”€â”€ research_agent.py      # Discover companies
â”‚   â”œâ”€â”€ enrichment_agent.py    # Gather details
â”‚   â””â”€â”€ scoring_agent.py       # Evaluate & rank
â”œâ”€â”€ prompts/                    # LLM prompts
â”‚   â”œâ”€â”€ partner_discovery.txt
â”‚   â”œâ”€â”€ partner_scoring.txt
â”‚   â”œâ”€â”€ customer_discovery.txt
â”‚   â””â”€â”€ customer_scoring.txt
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ llm_client.py          # Ollama interface
â”‚   â”œâ”€â”€ search_client.py       # Tavily search
â”‚   â””â”€â”€ prompt_tracer.py       # Prompt logging
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ logs/                  # Application logs
â”‚   â”œâ”€â”€ prompt_logs/           # LLM traces
â”‚   â”œâ”€â”€ results_cache/         # Cached results
â”‚   â””â”€â”€ axlewave_context/      # Company context
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ GUIDE.md              # Complete guide
â”œâ”€â”€ orchestrator.py            # Main orchestrator
â”œâ”€â”€ app.py                     # Streamlit UI
â””â”€â”€ README.md                  # This file
```

## ğŸ® Usage

### Natural Language Queries

```
"Find me 10 automotive dealerships that would buy DealerFlow Cloud"
"Show me technology partners for vehicle history and valuation"
"Find me both customers and partners"
```

### Predefined Queries

Use buttons in the Streamlit UI:
- **Top 10 Potential Customers** - Find dealer groups
- **Top 10 Technology Partners** - Find integration partners
- **Both Customers and Partners** - Combined search

## ğŸ”§ Configuration

Edit `.env` file:

```bash
# LLM
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=mistral:7b

# Search
TAVILY_API_KEY=your_key_here

# Settings
LOG_LEVEL=INFO
CACHE_RESULTS=true
MAX_COMPANIES_TO_ANALYZE=30
```

Customize company profile: `data/axlewave_context/company_context.json`

## ğŸ¯ Key Features Explained

### Smart Filtering
- **Parent/subsidiary detection**: "AutoNation Inc." filters out "AutoNation Honda Chandler"
- **Fuzzy duplicate detection**: "Lithia Motors" and "Lithia & Driveway" recognized as same company
- **Competitor exclusion**: 16 DMS competitors filtered (CDK Global, Reynolds & Reynolds, etc.)

### Prompt Tracing
All LLM interactions logged to `data/prompt_logs/session_*.jsonl`:
```python
from utils.prompt_tracer import prompt_tracer
report = prompt_tracer.generate_report()
```

### Results Caching
Results saved to `data/results_cache/`:
- `customer_YYYYMMDD_HHMMSS.json`
- `partner_YYYYMMDD_HHMMSS.json`

## ğŸ“ˆ Performance

**Typical execution time:**
- Intent classification: 1-2 seconds
- Research (30 companies): 30-60 seconds
- Enrichment (30 companies): 60-90 seconds
- Scoring (30 companies): 30-45 seconds
- **Total: ~2-3 minutes for 10 results**

**Optimizations:**
- Results caching
- Parallel search execution
- Early filtering (40% fewer enrichment calls)
- Smart duplicate detection

## ğŸ“š Documentation

- **[Complete Guide](docs/GUIDE.md)** - Setup, architecture, usage, development
- **[Example Results](data/results_cache/)** - Customer & partner results

## ğŸ§ª Testing

Verify setup:
```bash
python test_setup.py
```

Test individual agents:
```bash
python -m agents.research_agent
python -m agents.scoring_agent
```

## ğŸ› Troubleshooting

**Ollama not running:**
```bash
ollama serve
ollama list  # Should show mistral:7b
```

**Tavily API errors:**
- Check API key in `.env`
- Verify quota at https://tavily.com/dashboard
- Free tier: 1,000 searches/month

**Poor results:**
1. Check logs: `data/logs/lead_generator.log`
2. Review prompt traces: `data/prompt_logs/`
3. Adjust prompts in `prompts/` directory

See [Complete Guide](docs/GUIDE.md) for detailed troubleshooting.

## ğŸ“ How It Works

1. **User input** â†’ Intent Classifier determines customer/partner/both
2. **Research Agent** â†’ Generates 6-8 search queries, executes Tavily searches
3. **Smart filtering** â†’ Removes competitors, duplicates, subsidiaries
4. **Enrichment Agent** â†’ Gathers company details (website, HQ, size)
5. **Scoring Agent** â†’ Evaluates fit (0-10), generates rationale
6. **Top 10 results** â†’ Cached and displayed

## ğŸš€ Next Steps

After installation:
1. Run predefined queries to see results
2. Explore cached results in `data/results_cache/`
3. Review prompt traces in `data/prompt_logs/`
4. Customize prompts in `prompts/` directory
5. Edit company profile in `data/axlewave_context/`

## ğŸ“ License

MIT License - See LICENSE file for details

## ğŸ¤ Contributing

This is a prototype/assignment project. For questions or improvements, please open an issue.

---

**Built with:** Ollama (Mistral 7B) â€¢ Tavily AI â€¢ Streamlit â€¢ Python 3.9+
