# LLM Configuration
# Option 1: Ollama (Local - recommended)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b  # or mistral:7b, mixtral:8x7b

# Option 2: HuggingFace (if using HF Inference API)
HUGGINGFACE_API_TOKEN=your_token_here
HUGGINGFACE_MODEL=mistralai/Mistral-7B-Instruct-v0.2

# Search API Configuration
# Tavily AI Search - AI-optimized search for LLM applications
# Free tier: 1,000 searches/month
# Sign up: https://tavily.com
TAVILY_API_KEY=your_tavily_key_here

# Prompt Tracing
LANGFUSE_PUBLIC_KEY=your_public_key
LANGFUSE_SECRET_KEY=your_secret_key
LANGFUSE_HOST=https://cloud.langfuse.com

# Application Settings
LOG_LEVEL=INFO
CACHE_RESULTS=true
MAX_COMPANIES_TO_ANALYZE=30
